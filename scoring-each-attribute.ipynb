{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* A good way to assess each post on how they keep being accessible for people with special needs, is to rate them using a percentage of how accessible they are.\n",
        "\n",
        "* So, this Notebook gives weights on all the different kinds of problems that descriptions may have, so that we can know how accessible each post is."
      ],
      "metadata": {
        "id": "hn06Lu7ga-Ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the first 2 cells to import or install any necessary dependencies\n",
        "!pip install emoji"
      ],
      "metadata": {
        "id": "3v0Cy6X-EgdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import ast\n",
        "from transformers import pipeline\n",
        "import requests\n",
        "import regex as re\n",
        "import unicodedata\n",
        "import emoji"
      ],
      "metadata": {
        "id": "pwP6ZspUojzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giWa29NysaE2"
      },
      "outputs": [],
      "source": [
        "# Upload CSV on Colab, then write click on the file, select copy path and paste it below\n",
        "\n",
        "csv_url = \"the CSV file\"\n",
        "df = pd.read_csv(csv_url)\n",
        "\n",
        "# Create a folder named \"LLMHashtag\" and upload inside it the files for the\n",
        "# parameters of the Hashtag LLM\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"hashtag LLM\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"hashtag LLM\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "# Label mapping\n",
        "label_map = {\"LABEL_0\": \"Inaccessible\", \"LABEL_1\": \"Accessible\"}\n",
        "\n",
        "\n",
        "\n",
        "# Scoring Constants. These constants can give different importance on each topic\n",
        "# about the posts being accessible\n",
        "\n",
        "#Alt-text related\n",
        "SCORE_IF_ALT_TEXT_EMPTY = 0\n",
        "SCORE_IF_ALT_TEXT_IS_AI_GENERATED = 1\n",
        "SCORE_IF_ALT_TEXT_IS_CUSTOM_MADE = 4\n",
        "\n",
        "#Hashtag related\n",
        "SCORE_IF_HASHTAG_IS_ACCESSIBLE = 5\n",
        "SCORE_IF_HASHTAG_IS_INACCESSIBLE = 0\n",
        "SCORE_IF_THERE_IS_NO_HASHTAG = 0\n",
        "SCORE_HASHTAGS_IN_LAST_LINE = 5\n",
        "SCORE_HASHTAGS_NOT_IN_LAST_LINE = 0\n",
        "SCORE_HASHTAG_COUNT_OK = 3\n",
        "SCORE_HASHTAG_COUNT_TOO_MANY = 0\n",
        "\n",
        "#Font related\n",
        "SCORE_IF_FONT_IS_SIMPLE = 1\n",
        "SCORE_IF_FONT_IS_FANCY = 0\n",
        "\n",
        "#Emoji related\n",
        "SCORE_IF_NUMBER_OF_EMOJIS_IS_ACCEPTABLE = 1\n",
        "SCORE_IF_NUMBER_OF_EMOJIS_IS_NOT_ACCEPTABLE = 0\n",
        "\n",
        "\n",
        "# This function uses the LLM to check if each hashtag is accesible or not\n",
        "def score_hashtags_from_list(row):\n",
        "    try:\n",
        "        hashtags = ast.literal_eval(row)\n",
        "        if not isinstance(hashtags, list) or not hashtags:\n",
        "            return SCORE_IF_THERE_IS_NO_HASHTAG\n",
        "    except:\n",
        "        return SCORE_IF_THERE_IS_NO_HASHTAG\n",
        "\n",
        "    scores = []\n",
        "    for tag in hashtags:\n",
        "        result = classifier(tag)[0]\n",
        "        label = label_map[result[\"label\"]]\n",
        "        score = SCORE_IF_HASHTAG_IS_ACCESSIBLE if label == \"Accessible\" else SCORE_IF_HASHTAG_IS_INACCESSIBLE\n",
        "        scores.append(score)\n",
        "\n",
        "    return round(sum(scores) / len(scores), 2)\n",
        "\n",
        "# This function checks if the description is empty, AI-generated or custom-made\n",
        "def score_alt_text(alt_text):\n",
        "    if pd.isna(alt_text) or str(alt_text).strip() == \"\":\n",
        "        return SCORE_IF_ALT_TEXT_EMPTY\n",
        "    elif \"may be\" in str(alt_text).lower():\n",
        "        return SCORE_IF_ALT_TEXT_IS_AI_GENERATED\n",
        "    else:\n",
        "        return SCORE_IF_ALT_TEXT_IS_CUSTOM_MADE\n",
        "\n",
        "# This function checks if inside the description exist any different font than\n",
        "# the default one\n",
        "def is_fancy_font(text):\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        return SCORE_IF_FONT_IS_SIMPLE\n",
        "\n",
        "    for char in text:\n",
        "        if char.isalpha():\n",
        "            name = unicodedata.name(char, \"\")\n",
        "            if any(fancy in name for fancy in [\n",
        "                \"MATHEMATICAL\",\n",
        "                \"FULLWIDTH\",\n",
        "                \"DOUBLE-STRUCK\",\n",
        "                \"CIRCLED\",\n",
        "                \"SQUARED\",\n",
        "                \"MONOSPACE\",\n",
        "                \"FRAKTUR\",\n",
        "                \"SCRIPT\",\n",
        "            ]):\n",
        "                return SCORE_IF_FONT_IS_FANCY\n",
        "\n",
        "    return SCORE_IF_FONT_IS_SIMPLE\n",
        "\n",
        "emoji_pattern = re.compile(r'\\X', re.UNICODE)\n",
        "\n",
        "# This function checks if a description has more than 3 emojis in a row\n",
        "def has_excessive_emojis(text):\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        return SCORE_IF_NUMBER_OF_EMOJIS_IS_ACCEPTABLE\n",
        "\n",
        "    emoji_run = 0\n",
        "    for token in emoji_pattern.findall(text):\n",
        "        if emoji.is_emoji(token):\n",
        "            emoji_run += 1\n",
        "            # You can change the number of emojis that are acceptable by\n",
        "            # changing the number below\n",
        "            if emoji_run > 3:\n",
        "                return SCORE_IF_NUMBER_OF_EMOJIS_IS_NOT_ACCEPTABLE\n",
        "        else:\n",
        "            emoji_run = 0\n",
        "    return SCORE_IF_NUMBER_OF_EMOJIS_IS_ACCEPTABLE\n",
        "\n",
        "# This function checks if the hashtags in a description are grouped in the\n",
        "# last line\n",
        "def score_hashtags_last_line(description: str) -> int:\n",
        "    if not description or not isinstance(description, str):\n",
        "        return SCORE_HASHTAGS_IN_LAST_LINE\n",
        "\n",
        "    lines = [line.strip() for line in description.strip().splitlines() if line.strip()]\n",
        "    if not lines:\n",
        "        return SCORE_HASHTAGS_IN_LAST_LINE\n",
        "\n",
        "    all_hashtags = re.findall(r\"#\\w+\", description)\n",
        "    if not all_hashtags:\n",
        "        return SCORE_HASHTAGS_IN_LAST_LINE\n",
        "\n",
        "    last_line = lines[-1]\n",
        "    hashtags_in_last_line = re.findall(r\"#\\w+\", last_line)\n",
        "\n",
        "    if len(hashtags_in_last_line) == len(all_hashtags):\n",
        "        return SCORE_HASHTAGS_IN_LAST_LINE\n",
        "    else:\n",
        "        return SCORE_HASHTAGS_NOT_IN_LAST_LINE\n",
        "\n",
        "# This function checks the number of hastags that exist in a description\n",
        "def score_hashtag_count_limit(description: str) -> int:\n",
        "    if not description or not isinstance(description, str):\n",
        "        return SCORE_HASHTAG_COUNT_OK\n",
        "\n",
        "    hashtags = re.findall(r\"#\\w+\", description)\n",
        "    # You can change the acceptable number of hashtags in a description\n",
        "    # by changing the number below\n",
        "    return SCORE_HASHTAG_COUNT_OK if len(hashtags) <= 5 else SCORE_HASHTAG_COUNT_TOO_MANY\n",
        "\n",
        "\n",
        "df[\"alt_text\"] = df[\"alt_text\"].fillna(\"\")\n",
        "df[\"hashtags\"] = df[\"hashtags\"].fillna(\"[]\")\n",
        "df[\"description\"] = df[\"description\"].fillna(\"\")\n",
        "\n",
        "df['alt_text_score'] = df['alt_text'].apply(score_alt_text)\n",
        "df[\"hashtag_score\"] = df[\"hashtags\"].apply(score_hashtags_from_list)\n",
        "df[\"font_style_score\"] = df[\"description\"].apply(is_fancy_font)\n",
        "df[\"emoji_row_score\"] = df[\"description\"].apply(has_excessive_emojis)\n",
        "df[\"hashtag_last_line_score\"] = df[\"description\"].apply(score_hashtags_last_line)\n",
        "df[\"hashtag_count_score\"] = df[\"description\"].apply(score_hashtag_count_limit)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"user_posted\": df[\"user_posted\"],\n",
        "    'alt_text_score': df['alt_text_score'],\n",
        "    'hashtag_score': df['hashtag_score'],\n",
        "    \"font_style_score\": df[\"font_style_score\"],\n",
        "    \"emoji_row_score\": df[\"emoji_row_score\"],\n",
        "    \"hashtag_last_line_score\": df[\"hashtag_last_line_score\"],\n",
        "    \"hashtag_count_score\": df[\"hashtag_count_score\"]\n",
        "\n",
        "})\n",
        "results.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Score Aggregation and Normalization\n",
        "\n",
        "# Define all score column names\n",
        "score_columns = [\n",
        "    'alt_text_score',\n",
        "    'hashtag_score',\n",
        "    'font_style_score',\n",
        "    'emoji_row_score',\n",
        "    'hashtag_last_line_score',\n",
        "    'hashtag_count_score',\n",
        "]\n",
        "\n",
        "# Sum the raw scores\n",
        "df[\"raw_score_total\"] = df[score_columns].sum(axis=1)\n",
        "\n",
        "# Normalize so the highest score is 100\n",
        "\n",
        "#!max_score = df[\"raw_score_total\"].max()\n",
        "#!df[\"final_score\"] = df[\"raw_score_total\"] / max_score * 100\n",
        "\n",
        "# Use raw score as final score without normalization\n",
        "df[\"final_score\"] = df[\"raw_score_total\"].round(2)\n",
        "\n",
        "#View the top 50 results\n",
        "display(df[[\"user_posted\", \"final_score\"]].head(50))\n",
        "\n",
        "# Save to CSV\n",
        "df[[\"user_posted\"] + score_columns + [\"final_score\"]].to_csv(\"/content/final_scores_per_post.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "1Z2S3KoIM6Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Per-User Final Score Aggregation and Normalization\n",
        "\n",
        "\n",
        "# Define score columns\n",
        "score_columns = [\n",
        "    'alt_text_score',\n",
        "    'hashtag_score',\n",
        "    'font_style_score',\n",
        "    'emoji_row_score',\n",
        "    'hashtag_last_line_score',\n",
        "    'hashtag_count_score',\n",
        "]\n",
        "\n",
        "# Step 1: Count posts per user\n",
        "post_counts = df[\"user_posted\"].value_counts().reset_index()\n",
        "post_counts.columns = [\"user_posted\", \"post_count\"]\n",
        "\n",
        "# Step 2: Keep only users with ≥10 posts\n",
        "eligible_users = post_counts[post_counts[\"post_count\"] >= 10][\"user_posted\"]\n",
        "df_filtered = df[df[\"user_posted\"].isin(eligible_users)]\n",
        "\n",
        "# Step 3: Group and calculate per-user average scores\n",
        "user_scores = df_filtered.groupby(\"user_posted\")[score_columns].mean().reset_index()\n",
        "\n",
        "# Step 4: Merge with post counts\n",
        "user_scores = user_scores.merge(post_counts, on=\"user_posted\")\n",
        "\n",
        "# Step 5: Compute total raw score and normalize\n",
        "user_scores[\"raw_score_total\"] = user_scores[score_columns].sum(axis=1)\n",
        "max_score = user_scores[\"raw_score_total\"].max()\n",
        "user_scores[\"final_score\"] = (user_scores[\"raw_score_total\"] / max_score * 100).round(2)\n",
        "\n",
        "# Step 6: Show top results\n",
        "print(user_scores[[\"user_posted\", \"post_count\", \"final_score\"]].sort_values(by=\"final_score\", ascending=False).head(50))\n",
        "\n",
        "# Step 7: Save to CSV\n",
        "user_scores.to_csv(\"/content/user_normalized_final_scores.csv\", index=False)\n",
        "\n",
        "user_scores.to_csv(\"/content/final_scores_per_user.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "d2O63iCNbybf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}